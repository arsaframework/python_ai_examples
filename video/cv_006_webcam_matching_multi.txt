#https://docs.opencv.org/4.5.2/dc/dc3/tutorial_py_matcher.html

import cv2
import numpy as np
from sys import platform

#======================================
# function area
#======================================
def get_kp_desc(caption, filename, feature, img=None):
	if img is None:
		img = cv2.imread(filename)
	kp, des = feature.detectAndCompute(img, None)
	st = []
	st.append(caption)
	st.append(filename)
	st.append(img)	
	st.append(kp)
	st.append(des)
	return st

def trains_list(imgs, feature):
	trains = []
	for img in imgs:
		point_desc = get_kp_desc(img[0], img[1], feature)
		trains.append(point_desc)
	return trains

def get_good_points( desc_query, desc_trained, matcher ):
	matches = matcher.knnMatch(desc_query,desc_trained,k=2)
	good = []
	for m,n in matches:
		if m.distance < 0.75*n.distance: #0.75 from opencv doc
			good.append([m])
	return good

def query_good_point(img_query, train_list, matcher):
	count = 0
	good_idx = -1	
	goodpoint_ret = []
	good_max = 0
	for train in train_list:
		goodpoint = get_good_points( img_query[4], train[4], matcher ) #4 = desc
		if len(goodpoint) > good_max:
			good_max = len(goodpoint)
			goodpoint_ret = goodpoint
			good_idx = count
		count += 1
	return good_idx, goodpoint_ret

def draw_debug_matched(query_data, trained_data, good_data):
	img3 = cv2.drawMatchesKnn(query_data[2],query_data[3],trained_data[2],trained_data[3],good_data,None,flags=2)
	#img3 = trained_data[2]
	cv2.putText(img3, trained_data[0] + " Pt: "+str(len(good_data)) ,(10,30), cv2.FONT_HERSHEY_COMPLEX, .7, (255,0,0), 2)
	return img3

#======================================
# main
#======================================
#use ORB and BF algorithms for get keypoint, description and matching
feature = cv2.ORB_create(nfeatures=1000) #fast, cheap
maxf = feature.getMaxFeatures()
#feature = cv2.ORB_create(WTA_K=4) #for NORM_HAMMING2 only when create BFMatcher()
#feature = cv2.SIFT_create() #slow, acc
#feature = cv2.AKAZE_create() #slow, acc
#feature = cv2.BRISK_create()  #veryslow, acc

bf = cv2.BFMatcher(cv2.NORM_HAMMING) #fast acc, if roi setting then result is best
#bf = cv2.BFMatcher(cv2.NORM_HAMMING2) #need set WTA_K=4 in ORB_create()
#bf = cv2.BFMatcher(cv2.NORM_L2SQR) #not good
#bf = cv2.BFMatcher(cv2.NORM_L2) #not good
#bf = cv2.BFMatcher(cv2.NORM_INF) #error



#list of image and caption for training data set
img_list = [ ["DirectX First! book.","game_book/DirectX_cover.jpg"], 
			["DirectX First!","game_book/DirectX_back.jpg"], 
			["Advanced DirectX","game_book/Advanced DirectX_cover.jpg"],
			["Advanced DirectX","game_book/Advanced DirectX_back.jpg"], 
			["Games Programming EP:1","game_book/Episode1_cover.jpg"],
			["Games Programming EP:1","game_book/Episode1_back.jpg"],
			["Games Programming EP:2,3,4","game_book/Episode234_cover.jpg"],
			["Games Programming EP:2,3,4","game_book/Episode234_back.jpg"],
			["ARSA Framework: Master of ARSA Script","game_book/arsa_script.jpg"],
			["Game Development","game_book/arsa_gamedev.jpg"]]

#1. training data set
trained = trains_list(img_list, feature)

#open webcam device
video = cv2.VideoCapture(0)
w = 640
h = 480
video.set(3, w) # width
video.set(4, h) # height

while True:
	ret, img = video.read() #read frame from webcam
	
	if platform == "darwin":
		# OS X
		img = cv2.flip(img, 1) # flip horizontal
	elif platform == "win32":
		# Windows...
		img = cv2.flip(img, 0) # flip vertical
		#img = cv2.flip(img, 1) # flip horizontal

	#2. get keypoint and description from input image
	img_query = get_kp_desc("query", "webcam", feature, img)

	#3. query input from trained data
	idx, goodpoint = query_good_point(img_query, trained, bf)

	#4. draw debug info
	gsize = len(goodpoint)
	cv2.putText(img, trained[idx][0] + " Pt: "+str(gsize),(10,30), cv2.FONT_HERSHEY_COMPLEX, .7, (0,255,0), 2)
	cv2.putText(img, str((gsize*100)/maxf)+" %" ,(10,70), cv2.FONT_HERSHEY_COMPLEX, .7, (0,255,0), 2)
	cv2.imshow("image", img)

	if cv2.waitKey(10)&0xFF == ord('q'):
		break